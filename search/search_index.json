{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"T265 Tracking Camera Python Library","text":"<p>This library is to help to simplify your interaction with T265. The camera will be automatically initialized and closed.</p> <p>This is very minimalistic. The point is to provide the simplest possible way of using T265 cameras. </p>"},{"location":"#installation","title":"Installation","text":"<p>this library is pip installable <pre><code>pip install t265\n</code></pre></p>"},{"location":"#ver-01xx","title":"Ver. 0.1.xx","text":"<p>This library handles the frame transformation difference between the pyrealsense2 and ROS.  You can specify a camera by its serial number. If you want to use more than one T265, you can create multiple instances of Tracking().</p>"},{"location":"#starting-ver-018","title":"Starting Ver. 0.1.8","text":"<p>Now you can add any arbitrary frame transformation to the camera pose. This is useful when you want to add a transformation from the camera to the robot base. This is not trivial since the returned pose is the current camera frame with respect to the initial camera frame.  This means if you want to get the robot base pose with respect to the initial body frame, you need to add the transformation from the robot base to the camera frame.</p> <p>This is now handled by the library. </p> <p>Note</p> <p>This is only for the pose and velocity. Acceleration is not supported yet.</p>"},{"location":"#important-note","title":"Important Note","text":"<p>Important</p> <p>Starting Ver. 1.54.1 Intel has dropped supports for T265 entirely.  Hence, this library requires pyrealsense2 earlier than Ver. 2.53.1  Starting Ver 0.1.3 this is part of requirements.txt.</p>"},{"location":"#how-to-use","title":"How to use","text":"<p>Here is a sample code. For more details, please check the Tracking APIs. <pre><code>import time\nfrom t265 import Tracking\nmy_tracking = Tracking(camera_sn='133122110783') # Provide your camera serial number. It should be on the camera bottom. None will use the first camera found.\n\nmy_tracking.start_tracking()    # [Optional] start tracking. It will be called automatically when you call update_pose() first time.\n                                # this will retry connection (Default retry 5 times with 1sec interval)\n\nN = 10     # will show pose, vel, acc for 10 times\nfor _ in range(N):\n    my_tracking.update_pose(wait=True) # wait=True will block the code till you get data from camera.     \n    print(f'Is camera on: {my_tracking.is_camera_on()}')\n    print(f\"Camera_sn: {my_tracking.get_camera_sn()}\")\n\n    # Getting pose\n    print(f'Current pose: {my_tracking.get_translation()}')    # getting pose (x,y,z, quat_xyzw) 1 by 7 np.array\n    print(f\"Current pose: {my_tracking.get_translation(frame='ros')}\")    # getting pose in ros frame (camera/odom/sample) (x,y,z, quat_xyzw) 1 by 7 np.array\n    print(f'Current pose: {my_tracking.get_translation(rotation=None)}') # getting pose (x,y,z,) 1 by 3 np.array\n    print(f'Current pose: {my_tracking.get_translation(trans=False, rotation=\"xyz\")}') # getting pose (euler_xyz) 1 by 3 np.array\n    print(f'Current pose: {my_tracking.get_translation(trans=False, rotation=\"zyx\", degrees=True)}') # getting pose (euler_zyx) 1 by 3 np.array in degrees\n    print(f\"Current pose: {my_tracking.get_matrix()}\")    # getting pose Transformation matrix 4 by 4 np.array. [r11, r12, r13, tx, r21, r22, r23, ty, r31, r32, r33, tz, 0, 0, 0, 1]\n    print(f\"Current pose: {my_tracking.get_matrix(frame='ros')}\")    # getting pose Transformation matrix in ros frame (camera/odom/sample) 4 by 4 np.array\n\n    # Getting velocity and acceleration\n    print(f'Current velocity: {my_tracking.get_velocity()}')    # getting velocity (linear vel x, y, z, angular vel x, y, z)\n    print(f'Current acceleration: {my_tracking.get_acceleration()()}')  # getting velocity (linear acc x, y, z, angular acc x, y, z)\n\n    time.sleep(1)   # loop every 1sec\n</code></pre></p>"},{"location":"#note","title":"Note","text":"<p>You don't need to provide a camera serial number. If you don't provide it, the first camera found will be used. If you provide it, it'll error out if the specific camera is not found.</p> <p>You don't need to call <code>my_tracking.start_tracking()</code> since it will be called when you do <code>my_tracking.update_pose()</code> first time. You can, of course, call it by yourself, but calling it multiple times will throw an error.</p> <p>You don't need to call <code>my_tracking.stop_tracking()</code> to stop the camera since the class Tracking deconstructor will call it automatically.  You can, of course, call it by yourself, but calling it multiple times will throw an error.</p> <p>If you need to restart a camera, then you can call stop_tracking(), then call start_tracking().</p>"},{"location":"#framing","title":"Framing","text":"<p>Currently, the library supports 2 frames: t265 hardware and ros (camera/odom/sample). Velocity and acceleration are always in t265 hardware frame (to be implemented).</p> <p>Note</p> <p>Currently translation and velocity are supported. Acceleration is not supported yet.</p>"},{"location":"#adding-your-custom-frame","title":"Adding your Custom Frame","text":"<p>You can add your custom frame to the camera pose. This is useful when you want to add a transformation from the camera to the robot base. You must add a frame before starting the camera since the frame needs to be initialized.  <pre><code>from t265 import Tracking\nmy_tracking = Tracking() \nmy_tracking.add_custom_frames('my_frame', trans=None, rot=[90, 0, 90], rot_format='xyz', degrees=True, T=None)\nmy_tracking.start_tracking()\n</code></pre></p> <p>Note</p> <pre><code>For more information, please check the [Tracking APIs: add_custom_frame](./tracking.md/#t265.Tracking.Tracking.add_custom_frames).\n</code></pre>"},{"location":"frame_handler/","title":"Frame Handler APIs","text":""},{"location":"frame_handler/#t265.FrameHandler.FrameHandler","title":"<code>FrameHandler</code>","text":"Source code in <code>t265/FrameHandler.py</code> <pre><code>class FrameHandler:\n    def __init__(self, frame_name):\n        \"\"\"\n        Create a new FrameHandler object to manage the transformation between frames.\n\n        Args:\n            frame_name (str): The unique identifier of the frame.\n        \"\"\"\n        self.frame_name = frame_name\n        self.T_init = np.eye(4)\n        self.T_trans = np.eye(4)\n\n    def set_frame_transformation(self, trans=None, rot=None, rot_format='quat', degrees=False, T=None):\n        \"\"\"\n        Define the transformation matrix for this frame.\n\n        Args:\n            trans (np.array, optional): The translation vector [x, y, z]. Defaults to zero vector if not provided.\n            rot (np.array, optional): The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.\n            rot_format (str, optional): The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'.\n            degrees (bool, optional): Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).\n            T (np.array, optional): A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.\n        \"\"\"\n        if T is not None:\n            self.T_trans = T\n        else:\n            if trans is None:\n                trans = np.zeros(3)\n            if rot is None:\n                rot = np.eye(3)\n            rotation = self._convert_rotation(rot, rot_format=rot_format, from_degrees=degrees, format='matrix')\n\n            self.T_trans[:3, :3] = rotation\n            self.T_trans[0:3, 3] = trans\n\n    def set_init_frame(self,  trans=None, rot=None, rot_format='quat', degrees=False, T=None):\n        \"\"\"\n        Define the initial frame for the transformation.\n\n        Args:\n            trans (np.array, optional): The translation vector [x, y, z]. Defaults to zero vector if not provided.\n            rot (np.array, optional): The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.\n            rot_format (str, optional): The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'.\n            degrees (bool, optional): Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).\n            T (np.array, optional): A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.\n        \"\"\"\n        # If transformation matrix is provided, use it directly\n        if T is not None:\n            self.T_init = T\n        else:\n            # If no translation vector or rotation is provided, use default values\n            if trans is None:\n                trans = np.zeros(3)\n            if rot is None:\n                rot = np.eye(3)\n\n            # Convert the rotation to a rotation matrix\n            rotation = self._convert_rotation(rot, rot_format=rot_format, from_degrees=degrees, format='matrix')\n\n            # Combine the translation and rotation into the transformation matrix\n            self.T_init[:3, :3] = rotation\n            self.T_init[0:3, 3] = trans\n\n\n    def _convert_rotation(self, rot, rot_format='quat', from_degrees=False, format='matrix', to_degrees=False):\n        \"\"\"\n        Convert a rotation from one representation to another (e.g., quaternion to matrix, or Euler angles to quaternion).\n\n        Args:\n            rot (np.array): The rotation in its original representation.\n            rot_format (str): The format of the original rotation (e.g., 'quat', 'matrix', 'xyz').\n            from_degrees (bool): Indicates whether the rotation angles in the original representation are in degrees.\n            format (str): The desired format for the rotation.\n            to_degrees (bool): Indicates whether the rotation angles in the converted representation should be in degrees.\n\n        Returns:\n            np.array: The rotation in the desired format.\n        \"\"\"\n        # If the original rotation is in the wxyz format, reorder it to the xyzw format\n        if rot_format == 'wxyz':\n            rot = np.append(rot[1:], rot[0])\n            format = 'xyzw'\n\n        # Convert the rotation to a scipy Rotation object, based on the original format\n        if rot_format in ['quat', 'xyzw']:\n            rotation = R.from_quat(rot)\n        elif rot_format == 'matrix':\n            rotation = R.from_matrix(rot)\n        elif rot_format in ['xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ']:\n            rotation = R.from_euler(rot_format, rot, degrees=from_degrees)\n        else:\n            raise ValueError(f'Invalid rotation format: {rot_format}')\n\n        # Convert the Rotation object to the desired format\n        if format in ['quat', 'xyzw', 'wxyz']:\n            ret = rotation.as_quat()\n            if format == 'wxyz':\n                ret = np.append(ret[3], ret[0:3])\n        elif format == 'matrix':\n            ret = rotation.as_matrix()\n        elif format in ['xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ']:\n            ret = rotation.as_euler(format, degrees=to_degrees)\n        else:\n            raise ValueError(f'Invalid rotation format: {format}')\n\n        return ret\n\n    def convert(self, current_camera_frame, T_mat=True, angular=None, linear=None):\n        \"\"\"\n        Apply the frame transformation to the given frame, resulting in a transformed frame and, optionally, angular and linear velocities.\n\n        Args:\n            current_camera_frame (np.array): 4x4 transformation matrix of the current camera frame.\n            T_mat (bool, optional): If True, the resulting transformed frame matrix is included in the return tuple. Defaults to True.\n            angular (bool, optional): If True, the transformed angular velocity is included in the return tuple. Defaults to True.\n            linear (bool, optional): If True, the transformed linear velocity is included in the return tuple. Defaults to True.\n\n        Returns:\n            tuple: A tuple containing the transformed frame, angular velocity, and linear velocity as requested.\n                   The order of the returned items is as follows: transformed frame, angular velocity, linear velocity.\n        \"\"\"\n        T = self.transform(current_camera_frame, return_all_frames=False)\n        if angular is not None and linear is not None:\n            vel = self.transform_velocity(current_camera_frame, angular, linear)\n\n        if T_mat and angular is not None and linear is not None:\n            return T, vel\n        elif angular is not None and linear is not None:\n            return vel\n        else:\n            return T\n\n    def transform(self, current_camera_frame, return_all_frames=False):\n        \"\"\"\n        Apply the frame transformation to the given frame, resulting in a transformed frame.\n\n        Args:\n            current_camera_frame (np.array): 4x4 transformation matrix of the current camera frame.\n            return_all_frames (bool, optional): If True, returns a tuple of all intermediate transformation matrices. Defaults to False.\n\n        Returns:\n            np.array or tuple: If return_all_frames is False, this function returns a 4x4 transformation matrix to the target frame.\n                               If True, it returns a tuple containing all intermediate transformation matrices used in the process.\n        \"\"\"\n        # Compute the transformation matrix from the current frame to the target frame\n        c_T_ros = self.T_trans\n\n        # Get the transformation matrix of the current camera frame\n        E_T_ck = current_camera_frame\n\n        # Get the inverse transformation matrix of the initial frame\n        c0_T_E = self.T_init.transpose()\n\n        # Compute the transformation matrix from the initial frame to the current camera frame\n        c0_T_ck = c0_T_E @ E_T_ck\n\n        # Compute the transformation matrix from the target frame to the current camera frame\n        ros_T_c = c_T_ros.transpose()\n        ros0_T_ck = ros_T_c @ c0_T_ck\n\n        # Compute the transformation matrix from the target frame to the current frame\n        ros0_T_rosk = ros0_T_ck @ c_T_ros\n        T = ros0_T_rosk\n\n        # Return the final transformation matrix or all intermediate matrices, depending on the return_all_frames flag\n        if return_all_frames:\n            return T, ros0_T_rosk, ros0_T_ck, c0_T_ck, c0_T_E, E_T_ck, ros_T_c, c_T_ros\n        else:\n            return T\n\n    def transform_velocity(self, current_camera_frame, angular, linear):\n        \"\"\"\n        Transforms velocity components from the current camera frame to the target frame.\n\n        Args:\n            current_camera_frame (np.array): 4x4 transformation matrix of the current camera frame.\n            angular (np.array): Angular velocity vector [wx, wy, wz] in the initial frame.\n            linear (np.array): Linear velocity vector [vx, vy, vz] in the initial frame.\n\n        Returns:\n            np.array: The transformed velocity vector [wx', wy', wz', vx', vy', vz'] in the target frame.\n        \"\"\"\n        # Get all intermediate transformation matrices by calling the transform() method with return_all_frames=True\n        T, ros0_T_rosk, ros0_T_ck, c0_T_ck, c0_T_E, E_T_ck, ros_T_c, c_T_ros = self.transform(current_camera_frame, return_all_frames=True)\n\n        # Get the translation vector of the target frame relative to the current camera frame\n        c_p_ros = self.T_trans[0:3, 3].flatten()\n\n        # Get the rotation matrix from the intermediate transformation matrix (ros0_T_rosk)\n        ros0_R_rosk = ros0_T_rosk[0:3, 0:3]\n\n        # Get the rotation matrix from the inverse transformation matrix (E_T_ck) and transpose it to get the rotation matrix from the current camera frame to the initial frame (ck_R_E)\n        ck_R_E = E_T_ck[0:3, 0:3].transpose()\n\n        # Compute the angular velocity in the current camera frame by rotating the angular velocity from the initial frame to the current frame (ck_w_ck)\n        ck_w_ck = ck_R_E @ angular\n\n        # Compute the linear velocity in the current camera frame by rotating the linear velocity from the initial frame to the current frame (ck_v_ck)\n        ck_v_ck = ck_R_E @ linear\n\n        # Transform the angular velocity from the current camera frame to the target frame (ros0_w_ros)\n        ros0_w_ros = (ros0_R_rosk @ ck_w_ck).reshape(3, )\n\n        # Transform the linear velocity from the current camera frame to the target frame (ros0_v_ros)\n        ros0_v_ros = (ros0_R_rosk @ ck_v_ck + np.cross(ck_w_ck, c_p_ros)).reshape(3, )\n\n        # Return the transformed velocity vector, combining the transformed angular and linear velocities\n        return np.append(ros0_v_ros, ros0_w_ros)\n</code></pre>"},{"location":"frame_handler/#t265.FrameHandler.FrameHandler.__init__","title":"<code>__init__(frame_name)</code>","text":"<p>Create a new FrameHandler object to manage the transformation between frames.</p> <p>Parameters:</p> Name Type Description Default <code>frame_name</code> <code>str</code> <p>The unique identifier of the frame.</p> required Source code in <code>t265/FrameHandler.py</code> <pre><code>def __init__(self, frame_name):\n    \"\"\"\n    Create a new FrameHandler object to manage the transformation between frames.\n\n    Args:\n        frame_name (str): The unique identifier of the frame.\n    \"\"\"\n    self.frame_name = frame_name\n    self.T_init = np.eye(4)\n    self.T_trans = np.eye(4)\n</code></pre>"},{"location":"frame_handler/#t265.FrameHandler.FrameHandler.set_frame_transformation","title":"<code>set_frame_transformation(trans=None, rot=None, rot_format='quat', degrees=False, T=None)</code>","text":"<p>Define the transformation matrix for this frame.</p> <p>Parameters:</p> Name Type Description Default <code>trans</code> <code>array</code> <p>The translation vector [x, y, z]. Defaults to zero vector if not provided.</p> <code>None</code> <code>rot</code> <code>array</code> <p>The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.</p> <code>None</code> <code>rot_format</code> <code>str</code> <p>The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'.</p> <code>'quat'</code> <code>degrees</code> <code>bool</code> <p>Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).</p> <code>False</code> <code>T</code> <code>array</code> <p>A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.</p> <code>None</code> Source code in <code>t265/FrameHandler.py</code> <pre><code>def set_frame_transformation(self, trans=None, rot=None, rot_format='quat', degrees=False, T=None):\n    \"\"\"\n    Define the transformation matrix for this frame.\n\n    Args:\n        trans (np.array, optional): The translation vector [x, y, z]. Defaults to zero vector if not provided.\n        rot (np.array, optional): The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.\n        rot_format (str, optional): The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'.\n        degrees (bool, optional): Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).\n        T (np.array, optional): A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.\n    \"\"\"\n    if T is not None:\n        self.T_trans = T\n    else:\n        if trans is None:\n            trans = np.zeros(3)\n        if rot is None:\n            rot = np.eye(3)\n        rotation = self._convert_rotation(rot, rot_format=rot_format, from_degrees=degrees, format='matrix')\n\n        self.T_trans[:3, :3] = rotation\n        self.T_trans[0:3, 3] = trans\n</code></pre>"},{"location":"frame_handler/#t265.FrameHandler.FrameHandler.set_init_frame","title":"<code>set_init_frame(trans=None, rot=None, rot_format='quat', degrees=False, T=None)</code>","text":"<p>Define the initial frame for the transformation.</p> <p>Parameters:</p> Name Type Description Default <code>trans</code> <code>array</code> <p>The translation vector [x, y, z]. Defaults to zero vector if not provided.</p> <code>None</code> <code>rot</code> <code>array</code> <p>The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.</p> <code>None</code> <code>rot_format</code> <code>str</code> <p>The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'.</p> <code>'quat'</code> <code>degrees</code> <code>bool</code> <p>Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).</p> <code>False</code> <code>T</code> <code>array</code> <p>A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.</p> <code>None</code> Source code in <code>t265/FrameHandler.py</code> <pre><code>def set_init_frame(self,  trans=None, rot=None, rot_format='quat', degrees=False, T=None):\n    \"\"\"\n    Define the initial frame for the transformation.\n\n    Args:\n        trans (np.array, optional): The translation vector [x, y, z]. Defaults to zero vector if not provided.\n        rot (np.array, optional): The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.\n        rot_format (str, optional): The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'.\n        degrees (bool, optional): Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).\n        T (np.array, optional): A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.\n    \"\"\"\n    # If transformation matrix is provided, use it directly\n    if T is not None:\n        self.T_init = T\n    else:\n        # If no translation vector or rotation is provided, use default values\n        if trans is None:\n            trans = np.zeros(3)\n        if rot is None:\n            rot = np.eye(3)\n\n        # Convert the rotation to a rotation matrix\n        rotation = self._convert_rotation(rot, rot_format=rot_format, from_degrees=degrees, format='matrix')\n\n        # Combine the translation and rotation into the transformation matrix\n        self.T_init[:3, :3] = rotation\n        self.T_init[0:3, 3] = trans\n</code></pre>"},{"location":"frame_handler/#t265.FrameHandler.FrameHandler.convert","title":"<code>convert(current_camera_frame, T_mat=True, angular=None, linear=None)</code>","text":"<p>Apply the frame transformation to the given frame, resulting in a transformed frame and, optionally, angular and linear velocities.</p> <p>Parameters:</p> Name Type Description Default <code>current_camera_frame</code> <code>array</code> <p>4x4 transformation matrix of the current camera frame.</p> required <code>T_mat</code> <code>bool</code> <p>If True, the resulting transformed frame matrix is included in the return tuple. Defaults to True.</p> <code>True</code> <code>angular</code> <code>bool</code> <p>If True, the transformed angular velocity is included in the return tuple. Defaults to True.</p> <code>None</code> <code>linear</code> <code>bool</code> <p>If True, the transformed linear velocity is included in the return tuple. Defaults to True.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the transformed frame, angular velocity, and linear velocity as requested.    The order of the returned items is as follows: transformed frame, angular velocity, linear velocity.</p> Source code in <code>t265/FrameHandler.py</code> <pre><code>def convert(self, current_camera_frame, T_mat=True, angular=None, linear=None):\n    \"\"\"\n    Apply the frame transformation to the given frame, resulting in a transformed frame and, optionally, angular and linear velocities.\n\n    Args:\n        current_camera_frame (np.array): 4x4 transformation matrix of the current camera frame.\n        T_mat (bool, optional): If True, the resulting transformed frame matrix is included in the return tuple. Defaults to True.\n        angular (bool, optional): If True, the transformed angular velocity is included in the return tuple. Defaults to True.\n        linear (bool, optional): If True, the transformed linear velocity is included in the return tuple. Defaults to True.\n\n    Returns:\n        tuple: A tuple containing the transformed frame, angular velocity, and linear velocity as requested.\n               The order of the returned items is as follows: transformed frame, angular velocity, linear velocity.\n    \"\"\"\n    T = self.transform(current_camera_frame, return_all_frames=False)\n    if angular is not None and linear is not None:\n        vel = self.transform_velocity(current_camera_frame, angular, linear)\n\n    if T_mat and angular is not None and linear is not None:\n        return T, vel\n    elif angular is not None and linear is not None:\n        return vel\n    else:\n        return T\n</code></pre>"},{"location":"frame_handler/#t265.FrameHandler.FrameHandler.transform","title":"<code>transform(current_camera_frame, return_all_frames=False)</code>","text":"<p>Apply the frame transformation to the given frame, resulting in a transformed frame.</p> <p>Parameters:</p> Name Type Description Default <code>current_camera_frame</code> <code>array</code> <p>4x4 transformation matrix of the current camera frame.</p> required <code>return_all_frames</code> <code>bool</code> <p>If True, returns a tuple of all intermediate transformation matrices. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>np.array or tuple: If return_all_frames is False, this function returns a 4x4 transformation matrix to the target frame.                If True, it returns a tuple containing all intermediate transformation matrices used in the process.</p> Source code in <code>t265/FrameHandler.py</code> <pre><code>def transform(self, current_camera_frame, return_all_frames=False):\n    \"\"\"\n    Apply the frame transformation to the given frame, resulting in a transformed frame.\n\n    Args:\n        current_camera_frame (np.array): 4x4 transformation matrix of the current camera frame.\n        return_all_frames (bool, optional): If True, returns a tuple of all intermediate transformation matrices. Defaults to False.\n\n    Returns:\n        np.array or tuple: If return_all_frames is False, this function returns a 4x4 transformation matrix to the target frame.\n                           If True, it returns a tuple containing all intermediate transformation matrices used in the process.\n    \"\"\"\n    # Compute the transformation matrix from the current frame to the target frame\n    c_T_ros = self.T_trans\n\n    # Get the transformation matrix of the current camera frame\n    E_T_ck = current_camera_frame\n\n    # Get the inverse transformation matrix of the initial frame\n    c0_T_E = self.T_init.transpose()\n\n    # Compute the transformation matrix from the initial frame to the current camera frame\n    c0_T_ck = c0_T_E @ E_T_ck\n\n    # Compute the transformation matrix from the target frame to the current camera frame\n    ros_T_c = c_T_ros.transpose()\n    ros0_T_ck = ros_T_c @ c0_T_ck\n\n    # Compute the transformation matrix from the target frame to the current frame\n    ros0_T_rosk = ros0_T_ck @ c_T_ros\n    T = ros0_T_rosk\n\n    # Return the final transformation matrix or all intermediate matrices, depending on the return_all_frames flag\n    if return_all_frames:\n        return T, ros0_T_rosk, ros0_T_ck, c0_T_ck, c0_T_E, E_T_ck, ros_T_c, c_T_ros\n    else:\n        return T\n</code></pre>"},{"location":"frame_handler/#t265.FrameHandler.FrameHandler.transform_velocity","title":"<code>transform_velocity(current_camera_frame, angular, linear)</code>","text":"<p>Transforms velocity components from the current camera frame to the target frame.</p> <p>Parameters:</p> Name Type Description Default <code>current_camera_frame</code> <code>array</code> <p>4x4 transformation matrix of the current camera frame.</p> required <code>angular</code> <code>array</code> <p>Angular velocity vector [wx, wy, wz] in the initial frame.</p> required <code>linear</code> <code>array</code> <p>Linear velocity vector [vx, vy, vz] in the initial frame.</p> required <p>Returns:</p> Type Description <p>np.array: The transformed velocity vector [wx', wy', wz', vx', vy', vz'] in the target frame.</p> Source code in <code>t265/FrameHandler.py</code> <pre><code>def transform_velocity(self, current_camera_frame, angular, linear):\n    \"\"\"\n    Transforms velocity components from the current camera frame to the target frame.\n\n    Args:\n        current_camera_frame (np.array): 4x4 transformation matrix of the current camera frame.\n        angular (np.array): Angular velocity vector [wx, wy, wz] in the initial frame.\n        linear (np.array): Linear velocity vector [vx, vy, vz] in the initial frame.\n\n    Returns:\n        np.array: The transformed velocity vector [wx', wy', wz', vx', vy', vz'] in the target frame.\n    \"\"\"\n    # Get all intermediate transformation matrices by calling the transform() method with return_all_frames=True\n    T, ros0_T_rosk, ros0_T_ck, c0_T_ck, c0_T_E, E_T_ck, ros_T_c, c_T_ros = self.transform(current_camera_frame, return_all_frames=True)\n\n    # Get the translation vector of the target frame relative to the current camera frame\n    c_p_ros = self.T_trans[0:3, 3].flatten()\n\n    # Get the rotation matrix from the intermediate transformation matrix (ros0_T_rosk)\n    ros0_R_rosk = ros0_T_rosk[0:3, 0:3]\n\n    # Get the rotation matrix from the inverse transformation matrix (E_T_ck) and transpose it to get the rotation matrix from the current camera frame to the initial frame (ck_R_E)\n    ck_R_E = E_T_ck[0:3, 0:3].transpose()\n\n    # Compute the angular velocity in the current camera frame by rotating the angular velocity from the initial frame to the current frame (ck_w_ck)\n    ck_w_ck = ck_R_E @ angular\n\n    # Compute the linear velocity in the current camera frame by rotating the linear velocity from the initial frame to the current frame (ck_v_ck)\n    ck_v_ck = ck_R_E @ linear\n\n    # Transform the angular velocity from the current camera frame to the target frame (ros0_w_ros)\n    ros0_w_ros = (ros0_R_rosk @ ck_w_ck).reshape(3, )\n\n    # Transform the linear velocity from the current camera frame to the target frame (ros0_v_ros)\n    ros0_v_ros = (ros0_R_rosk @ ck_v_ck + np.cross(ck_w_ck, c_p_ros)).reshape(3, )\n\n    # Return the transformed velocity vector, combining the transformed angular and linear velocities\n    return np.append(ros0_v_ros, ros0_w_ros)\n</code></pre>"},{"location":"framing/","title":"Frame Translation","text":"<p>\\(\\text{transform}(\\text{current\\_camera\\_frame}, \\text{return\\_all\\_frames}=\\text{False})\\)</p>"},{"location":"framing/#transformation-matrix-definition","title":"Transformation Matrix definition:","text":"<ol> <li>\\(T_{\\text{c}}^{\\text{ros}}\\) \u2014 Transformation matrix from the camera frame to the ROS frame. (A constant)</li> <li>\\(T_{\\text{E}}^{\\text{c}_k}\\) \u2014 Transformation matrix of the current camera frame.</li> <li>\\(T_{\\text{E}}^{\\text{c}_0}\\) = Transformation matrix of the initial camera frame with respect to the Earth frame.</li> </ol>"},{"location":"framing/#transformation-calculations","title":"Transformation Calculations:","text":"<ol> <li>\\(T_{\\text{c}_k}^{\\text{c}_0} = T^{\\text{E}}_{\\text{c}_0} \\cdot T_{\\text{E}}^{\\text{c}_k}\\) \u2014 Transformation matrix from the initial frame to the current camera frame.</li> <li>\\(T^{\\text{c}_k}_{\\text{ros}_0} = T^{\\text{c}}_{\\text{ros}} \\cdot T^{\\text{c}_k}_{\\text{c}_0}\\) \u2014 Combined transformation matrix from the ROS frame to the current camera frame.</li> <li>\\(T^{\\text{ros}_k}_{\\text{ros}_0} = T^{\\text{c}_k}_{\\text{ros}_0} \\cdot T_{\\text{c}}^{\\text{ros}}\\) \u2014 Final transformation matrix from the ROS frame to the transformed current frame.</li> </ol>"},{"location":"framing/#apis-and-implementation","title":"APIs and implementation :","text":"<p>APIs</p>"},{"location":"tracking/","title":"Tracking class APIs","text":""},{"location":"tracking/#t265-frame","title":"T265 Frame","text":""},{"location":"tracking/#t265-body-frame","title":"T265 Body frame","text":"<p>The default frame T265 returns.</p> <p>Z pointing the opposite of the camera.</p> <pre><code>        Y\n        |   / Z\n        |  /\n        | /\n X______|/\n</code></pre>"},{"location":"tracking/#ros-frame","title":"ROS frame","text":"<p>The default frame T265 returns if you use ros package.</p> <p>Y pointing out of the camera. VR convention.</p> <pre><code>    Z\n    |\n    |\n    |______ X\n   /\n  /\n Y\n</code></pre>"},{"location":"tracking/#apis","title":"APIs","text":""},{"location":"tracking/#t265.Tracking.Tracking","title":"<code>Tracking</code>","text":"Source code in <code>t265/Tracking.py</code> <pre><code>class Tracking:\n    def __init__(self, camera_sn=None, connection_retry=DEFAULT_CONNECTION_RETRY, retry_time=DEFAULT_RETRY_TIME,\n                 timeout=DEFAULT_TIMEOUT):\n        \"\"\"\n        Setting up the tracing camera. If you want to use multiple cameras, create multiple Tracking object instances.\n\n        Args:\n            camera_sn (str): Camera serial number. None for the first camera that is connected.\n            connection_retry (int): Retry times for connection.\n            retry_time (int): Retry time for connection in milliseconds.\n            timeout (int): Retry timeout for camera frame wait in milliseconds. If the camera does not respond in the given\n                           timeout, it will return the latest camera pose in the default frame.\n        \"\"\"\n        self.pose = None\n        self.camera_on = False\n        self.camera_sn = camera_sn\n        self.retry_time = retry_time / 1000  # Convert to seconds from milliseconds\n        self.TIMEOUT = timeout\n        self.pipe = rs.pipeline()\n        self._config_camera()\n        self.connection_retry = connection_retry\n        self.init_T = np.eye(4)\n        self.default_frames = DEFAULT_FRAMES\n        self.frames = dict()\n\n    def add_custom_frames(self, name, trans=None, rot=None, rot_format='quat', degrees=False, T=None):\n        \"\"\"\n        Define the transformation matrix for your custom frame. You can define as many frames as you want.\n        This is always from the camera frame to the custom frame.\n\n        Args:\n            trans (np.array, optional): The translation vector [x, y, z]. Defaults to zero vector if not provided.\n            rot (np.array, optional): The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.\n            rot_format (str, optional): The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'. Avaialble formats are 'quat', 'xyzw' (same as 'quat'), 'wxyz' (quat matlab format), 'matrix', 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ'.\n            degrees (bool, optional): Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).\n            T (np.array, optional): A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.\n\n        Examples:\n            &gt;&gt;&gt; # Define a custom frame named 'my_frame with a 90 degree rotation around the x-axis and z-axis\n            &gt;&gt;&gt; my_tracking.add_custom_frames('my_frame', rot=[90, 0, 90], rot_format='xyz', degrees=True)\n            &gt;&gt;&gt; # Define a custom frame named 'my_another_frame with an identity matrix\n            &gt;&gt;&gt; my_tracking.add_custom_frames('my_another_frame', T=np.eye(4))\n            &gt;&gt;&gt; # here is how to get the transformation matrix of the custom frame\n            &gt;&gt;&gt; my_tracking.get_matrix('my_frame')\n            &gt;&gt;&gt; my_tracking.get_matrix('my_another_frame')\n\n        Notes:\n            Your origin frame should be the camera frame. The transformation matrix is the custom frame with respect to the camera.\n        \"\"\"\n        if self.camera_on:\n            raise RuntimeError('Cannot add custom frames after the camera is started')\n        fh = FrameHandler(name)\n        fh.set_frame_transformation(trans, rot, rot_format, degrees, T)\n        self.frames[name] = fh\n\n    def start_tracking(self):\n        \"\"\"\n        Start tracking with the camera. It will retry for self.connection_retry times.\n        If you like to start tracking with a specific camera, set the camera_sn in the constructor.\n\n        Tips:\n            This will be called automatically when you call update_pose() for the first time.\n        \"\"\"\n        self.pipe.start(self.config)\n        for i in range(self.connection_retry):\n            try:\n                frames = self.pipe.wait_for_frames(self.TIMEOUT)\n                if frames.get_pose_frame() is not None:\n                    self.camera_on = True\n                    self.update_pose(wait=True)\n                    self.init_T = self.get_matrix()\n                    self._set_defualt_frames() # set the default frames\n                    self._init_frames()  # initialize all the frames associated\n                    self.get_camera_sn()\n                    break\n            except RuntimeError:\n                pass\n            except KeyboardInterrupt:\n                self.stop_tracking()\n            if i != 0:\n                logging.warning(f'T265 Camera retry {i}')\n            else:\n                logging.debug(f'T265 Camera Connected on the first try')\n            time.sleep(self.retry_time)\n        else:\n            raise ConnectionError(\"Camera communication errors\")\n\n    def _config_camera(self):\n        \"\"\"\n        Configure the camera.\n        \"\"\"\n        self.config = rs.config()\n        if self.camera_sn is None:\n            self.config.enable_stream(rs.stream.pose)\n        else:\n            self.config.enable_device(self.camera_sn)\n\n    def stop_tracking(self):\n        \"\"\"\n        Stop tracking with the camera. Safe closure.\n\n        Note:\n            This will be called automatically when Python exits.\n        \"\"\"\n        if self.camera_on:\n            self.pipe.stop()\n            self.camera_on = False\n\n    def update_pose(self, wait=True):\n        \"\"\"\n        Receive camera pose tracking information from the camera. you need to call this function to get the latest pose.\n        Then you can call get_translation(), get_velocity(), get_acceleration(), get_matrix() to get the pose, velocity, acceleration, and transformation matrix.\n\n\n        Args:\n            wait (bool): If True, waits for the next frame. Blocking call. Timeouts after self.TIMEOUT milliseconds.\n\n        Returns:\n            None\n        \"\"\"\n        if not self.camera_on:\n            self.start_tracking()\n        try:\n            if wait:\n                frames = self.pipe.wait_for_frames(self.TIMEOUT)\n            else:\n                frames = self.pipe.poll_for_frames()\n            self.pose = frames.get_pose_frame()\n        except RuntimeError:\n            pass\n        except KeyboardInterrupt:\n            self.stop_tracking()\n\n    def get_translation(self, frame=None, trans=True, rotation='quat', degrees=False):\n        \"\"\"\n        Get the translation of the camera.\n\n        Args:\n            frame (str): The frame of the translation. If frame is None, return the translation of the default frame.\n            trans (bool): If True, returns the translation.\n            rotation (str): Rotation format. 'quat', or Euler extrinsic: 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', and\n                intrinsic moving frame: 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ'.\n            degrees (bool): If True, the Euler angles are returned in degrees. ignored if rotation is 'quat'.\n\n        Returns:\n            np.array: [x, y, z, qx, qy, qz, qw] or [x, y, z, rx, ry, rz] for 'xyz' format. Follows the input Euler\n                      order in the output.\n        \"\"\"\n        ret = None\n        if frame is None:\n            ret = self._get_translation(trans, rotation, degrees)\n        else:\n            T = self.get_matrix(frame)\n            if T is not None:\n                t = T[0:3, 3].flatten()\n                q = R.from_matrix(T[0:3, 0:3]).as_quat()\n                ret = self._to_nparray(t, q, trans, rotation, degrees)\n        return ret\n\n    def _to_single_nparray(self, list_array):\n        if len(list_array) == 1:\n            return list_array[0]\n        return np.append(*list_array)\n\n    def _get_translation(self, trans=True, rotation='quat', degrees=False):\n        \"\"\"\n        Private function to get the translation of the camera always in the default frame.\n\n        Args:\n            rotation (str): Rotation format. 'matrix', 'quat', or Euler 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx',\n                            'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ'.\n            degrees (bool): If True, the Euler angles are returned in degrees.\n\n        Returns:\n            np.array: [x, y, z, qx, qy, qz, qw]\n        \"\"\"\n        if self.pose:\n            t = self._vector2np(self.pose.get_pose_data().translation)\n            q = self._quat2np(self.pose.get_pose_data().rotation)\n            return self._to_nparray(t, q, trans, rotation, degrees)\n\n    def _to_nparray(self, t, q, trans, rotation, degrees):\n        \"\"\"\n        Convert translation and rotation to np.array.\n\n        Args:\n            t (np.array): Translation np.array([x, y, z]).\n            q (np.array): Quaternion np.array([x, y, z, w]).\n            trans (bool): If True, returns the translation.\n            rotation (str): Format of rotation. 'quat', or Euler 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', 'ZYX', 'ZXY',\n                            'YXZ', 'YZX', 'XZY', 'XYZ'.\n            degrees (bool): If True, the Euler angles are returned in degrees.\n\n        Returns:\n            np.array: Flat np.array([x, y, z, qx, qy, qz, qw]) or np.array([x, y, z, rx, ry, rz]) for 'xyz' format.\n                      Follows the input Euler order in the output.\n        \"\"\"\n        ret_list = []\n        if trans:\n            ret_list.append(t)\n        if rotation is not None:\n            ret_list.append(self._quat2other(q, format=rotation, degrees=degrees))\n        return self._to_single_nparray(ret_list)\n\n    def get_velocity(self, frame=None):\n        \"\"\"\n        Get the velocity of the camera.\n\n        Returns:\n            np.array: [vx, vy, vz, wx, wy, wz]\n        \"\"\"\n        if self.pose:\n            vel = self._vector2np(self.pose.get_pose_data().velocity)\n            ang_vel = self._vector2np(self.pose.get_pose_data().angular_velocity)\n            if frame is not None:\n                T = self.get_matrix()\n                all_vel = self._convert_frame(frame, T, T_mat=False, angular=ang_vel, linear=vel)\n            else:\n                all_vel = np.append(vel, ang_vel)\n\n            return all_vel\n\n    def get_acceleration(self, frame=None) -&gt; np.ndarray:\n        \"\"\"\n        Get the acceleration of the camera.\n\n        Returns:\n            np.array: [ax, ay, az, awx, awy, awz]\n        \"\"\"\n        if self.pose:\n            acc = self._vector2np(self.pose.get_pose_data().acceleration)\n            ang_acc = self._vector2np(self.pose.get_pose_data().angular_acceleration)\n\n            if frame is not None:\n                raise NotImplementedError('Acceleration conversion is not implemented yet')\n            return np.append(acc, ang_acc)\n\n    def get_matrix(self, frame=None) -&gt; np.ndarray:\n        \"\"\"\n        Get the transformation matrix of the camera in a specific frame.\n\n        Args:\n            frame (str): Frame of the transformation matrix. If frame is None, return the transformation matrix of\n                         the default frame.\n\n        Returns:\n            np.array: [r11, r12, r13, tx, r21, r22, r23, ty, r31, r32, r33, tz, 0, 0, 0, 1].reshape(4, 4)\n        \"\"\"\n        if self.pose:\n            trans = self._get_translation()\n            rot_mat = R.from_quat(trans[3:]).as_matrix()\n            T = np.eye(4)\n            T[0:3, 0:3] = rot_mat\n            T[0:3, 3] = trans[0:3]\n\n            if frame is not None:\n                T = self._convert_frame(frame, T, T_mat=True, angular=None, linear=None)\n\n            # if frame == 'ros':\n            #     rot = R.from_euler('xyz', [0, 90, 90], degrees=True).as_matrix()\n            #     c_T_ros = np.eye(4)\n            #     c_T_ros[0:3, 0:3] = rot\n            #\n            #     E_T_ck = T\n            #     c0_T_E = self.init_T.transpose()\n            #     c0_T_ck = c0_T_E @ E_T_ck\n            #     ros_T_c = c_T_ros.transpose()\n            #     ros0_T_ck = ros_T_c @ c0_T_ck\n            #     ros0_T_rosk = ros0_T_ck @ c_T_ros\n            #     T = ros0_T_rosk\n            return T\n\n    def _quat2other(self, quat, order: str = 'xyzw', format='matrix', degrees=False) -&gt; np.ndarray:\n        \"\"\"\n        Convert quaternion to other format.\n\n        Args:\n            quat (np.array): Quaternion np.array([x, y, z, w]) or np.array([w, x, y, z]).\n            order (str): Quaternion order, xyzw or wxyz.\n            format (str): Format to convert to. 'matrix', 'quat', or 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', 'ZYX',\n                          'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ'.\n            degrees (bool): If True, the Euler angles are returned in degrees.\n\n        Returns:\n            np.array: Whatever format you want.\n        \"\"\"\n        if order != 'xyzw':\n            quat = np.append(quat[1:], quat[0])\n        if format == 'matrix':\n            return R.from_quat(quat).as_matrix()\n        elif format == 'quat':\n            return quat\n        elif format in ['xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ']:\n            return R.from_quat(quat).as_euler(format, degrees=degrees)\n\n    def _vector2np(self, vector):\n        \"\"\"\n        Convert rs.vector to np.array.\n\n        Args:\n            vector (pyrealsense2.vector): The vector to convert.\n\n        Returns:\n            np.array: [x, y, z]\n        \"\"\"\n        return np.array([vector.x, vector.y, vector.z])\n\n    def _quat2np(self, quat, order: str = 'xyzw') -&gt; np.ndarray:\n        \"\"\"\n        Convert rs.quaternion to np.array.\n\n        Args:\n            quat (pyrealsense2.quaternion): The quaternion to convert.\n            order (str): xyzw or wxyz string.\n\n        Returns:\n            np.array: [x, y, z, w]\n        \"\"\"\n        if order == 'wxyz':\n            return np.array([quat.w, quat.x, quat.y, quat.z])\n        else:\n            return np.array([quat.x, quat.y, quat.z, quat.w])\n\n    def _set_defualt_frames(self) -&gt; None:\n        \"\"\"\n        Set the default frames.\n        \"\"\"\n        for name, frame in self.default_frames.items():\n            f = FrameHandler(name)\n            f.set_frame_transformation(**frame)\n            self.frames[name] = f\n\n    def _init_frames(self) -&gt; None:\n        \"\"\"\n        Initialize the frames.\n        \"\"\"\n        T = self.get_matrix()\n        for name, frame in self.frames.items():\n            frame.set_init_frame(T=T)\n\n    def _convert_frame(self, name, T, T_mat=True, angular=None, linear=None) -&gt; FrameHandler:\n        \"\"\"\n        Convert the frame to the given frame.\n\n        Args:\n            name (str): The name of the frame to convert to.\n            T (np.array): The transformation matrix.\n\n        Returns:\n            FrameHandler: The converted frame.\n        \"\"\"\n        frame = self.frames.get(name)\n        if frame is None:\n            raise ValueError(f'Frame {frame} does not exist')\n        return frame.convert(current_camera_frame=T, T_mat=T_mat, angular=angular, linear=linear)\n\n    # Status functions\n    def is_camera_on(self) -&gt; bool:\n        \"\"\"\n        Check if the camera is on.\n\n        Returns:\n            bool: True if the camera is on.\n        \"\"\"\n        return self.camera_on\n\n    def get_camera_sn(self) -&gt; str:\n        \"\"\"\n        Get the camera serial number.\n\n        Returns:\n            str: Camera serial number.\n        \"\"\"\n        self.camera_sn = self.pipe.get_active_profile().get_device().get_info(rs.camera_info.serial_number)\n        return self.camera_sn\n\n    def __del__(self):\n        \"\"\"\n        Destructor: Turns off the camera upon Python exit.\n        \"\"\"\n        self.stop_tracking()\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.__init__","title":"<code>__init__(camera_sn=None, connection_retry=DEFAULT_CONNECTION_RETRY, retry_time=DEFAULT_RETRY_TIME, timeout=DEFAULT_TIMEOUT)</code>","text":"<p>Setting up the tracing camera. If you want to use multiple cameras, create multiple Tracking object instances.</p> <p>Parameters:</p> Name Type Description Default <code>camera_sn</code> <code>str</code> <p>Camera serial number. None for the first camera that is connected.</p> <code>None</code> <code>connection_retry</code> <code>int</code> <p>Retry times for connection.</p> <code>DEFAULT_CONNECTION_RETRY</code> <code>retry_time</code> <code>int</code> <p>Retry time for connection in milliseconds.</p> <code>DEFAULT_RETRY_TIME</code> <code>timeout</code> <code>int</code> <p>Retry timeout for camera frame wait in milliseconds. If the camera does not respond in the given            timeout, it will return the latest camera pose in the default frame.</p> <code>DEFAULT_TIMEOUT</code> Source code in <code>t265/Tracking.py</code> <pre><code>def __init__(self, camera_sn=None, connection_retry=DEFAULT_CONNECTION_RETRY, retry_time=DEFAULT_RETRY_TIME,\n             timeout=DEFAULT_TIMEOUT):\n    \"\"\"\n    Setting up the tracing camera. If you want to use multiple cameras, create multiple Tracking object instances.\n\n    Args:\n        camera_sn (str): Camera serial number. None for the first camera that is connected.\n        connection_retry (int): Retry times for connection.\n        retry_time (int): Retry time for connection in milliseconds.\n        timeout (int): Retry timeout for camera frame wait in milliseconds. If the camera does not respond in the given\n                       timeout, it will return the latest camera pose in the default frame.\n    \"\"\"\n    self.pose = None\n    self.camera_on = False\n    self.camera_sn = camera_sn\n    self.retry_time = retry_time / 1000  # Convert to seconds from milliseconds\n    self.TIMEOUT = timeout\n    self.pipe = rs.pipeline()\n    self._config_camera()\n    self.connection_retry = connection_retry\n    self.init_T = np.eye(4)\n    self.default_frames = DEFAULT_FRAMES\n    self.frames = dict()\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.add_custom_frames","title":"<code>add_custom_frames(name, trans=None, rot=None, rot_format='quat', degrees=False, T=None)</code>","text":"<p>Define the transformation matrix for your custom frame. You can define as many frames as you want. This is always from the camera frame to the custom frame.</p> <p>Parameters:</p> Name Type Description Default <code>trans</code> <code>array</code> <p>The translation vector [x, y, z]. Defaults to zero vector if not provided.</p> <code>None</code> <code>rot</code> <code>array</code> <p>The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.</p> <code>None</code> <code>rot_format</code> <code>str</code> <p>The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'. Avaialble formats are 'quat', 'xyzw' (same as 'quat'), 'wxyz' (quat matlab format), 'matrix', 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ'.</p> <code>'quat'</code> <code>degrees</code> <code>bool</code> <p>Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).</p> <code>False</code> <code>T</code> <code>array</code> <p>A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Define a custom frame named 'my_frame with a 90 degree rotation around the x-axis and z-axis\n&gt;&gt;&gt; my_tracking.add_custom_frames('my_frame', rot=[90, 0, 90], rot_format='xyz', degrees=True)\n&gt;&gt;&gt; # Define a custom frame named 'my_another_frame with an identity matrix\n&gt;&gt;&gt; my_tracking.add_custom_frames('my_another_frame', T=np.eye(4))\n&gt;&gt;&gt; # here is how to get the transformation matrix of the custom frame\n&gt;&gt;&gt; my_tracking.get_matrix('my_frame')\n&gt;&gt;&gt; my_tracking.get_matrix('my_another_frame')\n</code></pre> Notes <p>Your origin frame should be the camera frame. The transformation matrix is the custom frame with respect to the camera.</p> Source code in <code>t265/Tracking.py</code> <pre><code>def add_custom_frames(self, name, trans=None, rot=None, rot_format='quat', degrees=False, T=None):\n    \"\"\"\n    Define the transformation matrix for your custom frame. You can define as many frames as you want.\n    This is always from the camera frame to the custom frame.\n\n    Args:\n        trans (np.array, optional): The translation vector [x, y, z]. Defaults to zero vector if not provided.\n        rot (np.array, optional): The rotation, represented as either a quaternion or Euler angles. Defaults to identity matrix if not provided.\n        rot_format (str, optional): The format of the rotation (e.g., 'quat', 'matrix', 'xyz'). Defaults to 'quat'. Avaialble formats are 'quat', 'xyzw' (same as 'quat'), 'wxyz' (quat matlab format), 'matrix', 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ'.\n        degrees (bool, optional): Indicates whether the rotation angles are in degrees. Defaults to False (i.e., angles are in radians).\n        T (np.array, optional): A precomputed 4x4 transformation matrix. If provided, 'trans' and 'rot' will be ignored. Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Define a custom frame named 'my_frame with a 90 degree rotation around the x-axis and z-axis\n        &gt;&gt;&gt; my_tracking.add_custom_frames('my_frame', rot=[90, 0, 90], rot_format='xyz', degrees=True)\n        &gt;&gt;&gt; # Define a custom frame named 'my_another_frame with an identity matrix\n        &gt;&gt;&gt; my_tracking.add_custom_frames('my_another_frame', T=np.eye(4))\n        &gt;&gt;&gt; # here is how to get the transformation matrix of the custom frame\n        &gt;&gt;&gt; my_tracking.get_matrix('my_frame')\n        &gt;&gt;&gt; my_tracking.get_matrix('my_another_frame')\n\n    Notes:\n        Your origin frame should be the camera frame. The transformation matrix is the custom frame with respect to the camera.\n    \"\"\"\n    if self.camera_on:\n        raise RuntimeError('Cannot add custom frames after the camera is started')\n    fh = FrameHandler(name)\n    fh.set_frame_transformation(trans, rot, rot_format, degrees, T)\n    self.frames[name] = fh\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.start_tracking","title":"<code>start_tracking()</code>","text":"<p>Start tracking with the camera. It will retry for self.connection_retry times. If you like to start tracking with a specific camera, set the camera_sn in the constructor.</p> Tips <p>This will be called automatically when you call update_pose() for the first time.</p> Source code in <code>t265/Tracking.py</code> <pre><code>def start_tracking(self):\n    \"\"\"\n    Start tracking with the camera. It will retry for self.connection_retry times.\n    If you like to start tracking with a specific camera, set the camera_sn in the constructor.\n\n    Tips:\n        This will be called automatically when you call update_pose() for the first time.\n    \"\"\"\n    self.pipe.start(self.config)\n    for i in range(self.connection_retry):\n        try:\n            frames = self.pipe.wait_for_frames(self.TIMEOUT)\n            if frames.get_pose_frame() is not None:\n                self.camera_on = True\n                self.update_pose(wait=True)\n                self.init_T = self.get_matrix()\n                self._set_defualt_frames() # set the default frames\n                self._init_frames()  # initialize all the frames associated\n                self.get_camera_sn()\n                break\n        except RuntimeError:\n            pass\n        except KeyboardInterrupt:\n            self.stop_tracking()\n        if i != 0:\n            logging.warning(f'T265 Camera retry {i}')\n        else:\n            logging.debug(f'T265 Camera Connected on the first try')\n        time.sleep(self.retry_time)\n    else:\n        raise ConnectionError(\"Camera communication errors\")\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.stop_tracking","title":"<code>stop_tracking()</code>","text":"<p>Stop tracking with the camera. Safe closure.</p> Note <p>This will be called automatically when Python exits.</p> Source code in <code>t265/Tracking.py</code> <pre><code>def stop_tracking(self):\n    \"\"\"\n    Stop tracking with the camera. Safe closure.\n\n    Note:\n        This will be called automatically when Python exits.\n    \"\"\"\n    if self.camera_on:\n        self.pipe.stop()\n        self.camera_on = False\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.update_pose","title":"<code>update_pose(wait=True)</code>","text":"<p>Receive camera pose tracking information from the camera. you need to call this function to get the latest pose. Then you can call get_translation(), get_velocity(), get_acceleration(), get_matrix() to get the pose, velocity, acceleration, and transformation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>wait</code> <code>bool</code> <p>If True, waits for the next frame. Blocking call. Timeouts after self.TIMEOUT milliseconds.</p> <code>True</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>t265/Tracking.py</code> <pre><code>def update_pose(self, wait=True):\n    \"\"\"\n    Receive camera pose tracking information from the camera. you need to call this function to get the latest pose.\n    Then you can call get_translation(), get_velocity(), get_acceleration(), get_matrix() to get the pose, velocity, acceleration, and transformation matrix.\n\n\n    Args:\n        wait (bool): If True, waits for the next frame. Blocking call. Timeouts after self.TIMEOUT milliseconds.\n\n    Returns:\n        None\n    \"\"\"\n    if not self.camera_on:\n        self.start_tracking()\n    try:\n        if wait:\n            frames = self.pipe.wait_for_frames(self.TIMEOUT)\n        else:\n            frames = self.pipe.poll_for_frames()\n        self.pose = frames.get_pose_frame()\n    except RuntimeError:\n        pass\n    except KeyboardInterrupt:\n        self.stop_tracking()\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.get_translation","title":"<code>get_translation(frame=None, trans=True, rotation='quat', degrees=False)</code>","text":"<p>Get the translation of the camera.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>str</code> <p>The frame of the translation. If frame is None, return the translation of the default frame.</p> <code>None</code> <code>trans</code> <code>bool</code> <p>If True, returns the translation.</p> <code>True</code> <code>rotation</code> <code>str</code> <p>Rotation format. 'quat', or Euler extrinsic: 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', and intrinsic moving frame: 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ'.</p> <code>'quat'</code> <code>degrees</code> <code>bool</code> <p>If True, the Euler angles are returned in degrees. ignored if rotation is 'quat'.</p> <code>False</code> <p>Returns:</p> Type Description <p>np.array: [x, y, z, qx, qy, qz, qw] or [x, y, z, rx, ry, rz] for 'xyz' format. Follows the input Euler       order in the output.</p> Source code in <code>t265/Tracking.py</code> <pre><code>def get_translation(self, frame=None, trans=True, rotation='quat', degrees=False):\n    \"\"\"\n    Get the translation of the camera.\n\n    Args:\n        frame (str): The frame of the translation. If frame is None, return the translation of the default frame.\n        trans (bool): If True, returns the translation.\n        rotation (str): Rotation format. 'quat', or Euler extrinsic: 'xyz', 'xzy', 'yxz', 'yzx', 'zxy', 'zyx', and\n            intrinsic moving frame: 'ZYX', 'ZXY', 'YXZ', 'YZX', 'XZY', 'XYZ'.\n        degrees (bool): If True, the Euler angles are returned in degrees. ignored if rotation is 'quat'.\n\n    Returns:\n        np.array: [x, y, z, qx, qy, qz, qw] or [x, y, z, rx, ry, rz] for 'xyz' format. Follows the input Euler\n                  order in the output.\n    \"\"\"\n    ret = None\n    if frame is None:\n        ret = self._get_translation(trans, rotation, degrees)\n    else:\n        T = self.get_matrix(frame)\n        if T is not None:\n            t = T[0:3, 3].flatten()\n            q = R.from_matrix(T[0:3, 0:3]).as_quat()\n            ret = self._to_nparray(t, q, trans, rotation, degrees)\n    return ret\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.get_velocity","title":"<code>get_velocity(frame=None)</code>","text":"<p>Get the velocity of the camera.</p> <p>Returns:</p> Type Description <p>np.array: [vx, vy, vz, wx, wy, wz]</p> Source code in <code>t265/Tracking.py</code> <pre><code>def get_velocity(self, frame=None):\n    \"\"\"\n    Get the velocity of the camera.\n\n    Returns:\n        np.array: [vx, vy, vz, wx, wy, wz]\n    \"\"\"\n    if self.pose:\n        vel = self._vector2np(self.pose.get_pose_data().velocity)\n        ang_vel = self._vector2np(self.pose.get_pose_data().angular_velocity)\n        if frame is not None:\n            T = self.get_matrix()\n            all_vel = self._convert_frame(frame, T, T_mat=False, angular=ang_vel, linear=vel)\n        else:\n            all_vel = np.append(vel, ang_vel)\n\n        return all_vel\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.get_acceleration","title":"<code>get_acceleration(frame=None)</code>","text":"<p>Get the acceleration of the camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.array: [ax, ay, az, awx, awy, awz]</p> Source code in <code>t265/Tracking.py</code> <pre><code>def get_acceleration(self, frame=None) -&gt; np.ndarray:\n    \"\"\"\n    Get the acceleration of the camera.\n\n    Returns:\n        np.array: [ax, ay, az, awx, awy, awz]\n    \"\"\"\n    if self.pose:\n        acc = self._vector2np(self.pose.get_pose_data().acceleration)\n        ang_acc = self._vector2np(self.pose.get_pose_data().angular_acceleration)\n\n        if frame is not None:\n            raise NotImplementedError('Acceleration conversion is not implemented yet')\n        return np.append(acc, ang_acc)\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.get_matrix","title":"<code>get_matrix(frame=None)</code>","text":"<p>Get the transformation matrix of the camera in a specific frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>str</code> <p>Frame of the transformation matrix. If frame is None, return the transformation matrix of          the default frame.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.array: [r11, r12, r13, tx, r21, r22, r23, ty, r31, r32, r33, tz, 0, 0, 0, 1].reshape(4, 4)</p> Source code in <code>t265/Tracking.py</code> <pre><code>def get_matrix(self, frame=None) -&gt; np.ndarray:\n    \"\"\"\n    Get the transformation matrix of the camera in a specific frame.\n\n    Args:\n        frame (str): Frame of the transformation matrix. If frame is None, return the transformation matrix of\n                     the default frame.\n\n    Returns:\n        np.array: [r11, r12, r13, tx, r21, r22, r23, ty, r31, r32, r33, tz, 0, 0, 0, 1].reshape(4, 4)\n    \"\"\"\n    if self.pose:\n        trans = self._get_translation()\n        rot_mat = R.from_quat(trans[3:]).as_matrix()\n        T = np.eye(4)\n        T[0:3, 0:3] = rot_mat\n        T[0:3, 3] = trans[0:3]\n\n        if frame is not None:\n            T = self._convert_frame(frame, T, T_mat=True, angular=None, linear=None)\n\n        # if frame == 'ros':\n        #     rot = R.from_euler('xyz', [0, 90, 90], degrees=True).as_matrix()\n        #     c_T_ros = np.eye(4)\n        #     c_T_ros[0:3, 0:3] = rot\n        #\n        #     E_T_ck = T\n        #     c0_T_E = self.init_T.transpose()\n        #     c0_T_ck = c0_T_E @ E_T_ck\n        #     ros_T_c = c_T_ros.transpose()\n        #     ros0_T_ck = ros_T_c @ c0_T_ck\n        #     ros0_T_rosk = ros0_T_ck @ c_T_ros\n        #     T = ros0_T_rosk\n        return T\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.is_camera_on","title":"<code>is_camera_on()</code>","text":"<p>Check if the camera is on.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the camera is on.</p> Source code in <code>t265/Tracking.py</code> <pre><code>def is_camera_on(self) -&gt; bool:\n    \"\"\"\n    Check if the camera is on.\n\n    Returns:\n        bool: True if the camera is on.\n    \"\"\"\n    return self.camera_on\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.get_camera_sn","title":"<code>get_camera_sn()</code>","text":"<p>Get the camera serial number.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Camera serial number.</p> Source code in <code>t265/Tracking.py</code> <pre><code>def get_camera_sn(self) -&gt; str:\n    \"\"\"\n    Get the camera serial number.\n\n    Returns:\n        str: Camera serial number.\n    \"\"\"\n    self.camera_sn = self.pipe.get_active_profile().get_device().get_info(rs.camera_info.serial_number)\n    return self.camera_sn\n</code></pre>"},{"location":"tracking/#t265.Tracking.Tracking.__del__","title":"<code>__del__()</code>","text":"<p>Destructor: Turns off the camera upon Python exit.</p> Source code in <code>t265/Tracking.py</code> <pre><code>def __del__(self):\n    \"\"\"\n    Destructor: Turns off the camera upon Python exit.\n    \"\"\"\n    self.stop_tracking()\n</code></pre>"}]}